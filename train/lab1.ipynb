{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 1 - Monty Hall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from typing import Optional\n",
    "\n",
    "\n",
    "np.random.seed(0)\n",
    "\n",
    "\n",
    "GAMES = 2 * 10 ** 5\n",
    "DOOR = {\n",
    "    'Left': 0,\n",
    "    'Mid': 1,\n",
    "    'Right': 2\n",
    "}\n",
    "\n",
    "\n",
    "class MHGame():\n",
    "    def __init__(self, size_n: np.int32, p: np.ndarray = np.array([1 / 3, 1 / 3, 1 / 3])) -> None:\n",
    "        self.__size_n = size_n\n",
    "        self.__prob = p\n",
    "        self.__prize = np.array([np.random.choice([DOOR['Left'], DOOR['Mid'], DOOR['Right']], p = self.__prob) for _ in range(size_n)])\n",
    "\n",
    "\n",
    "    def validate(self, model: callable, verbose: bool = False) -> np.float32:  \n",
    "        results = self.__simulate(self.__prize, model, self.__size_n)\n",
    "        accuracy = np.mean(results == self.__prize)\n",
    "        if verbose:\n",
    "            print(f'{model.get_model_name()} model: Acc -> {100 * accuracy:.3f}%')\n",
    "        return accuracy\n",
    "    \n",
    "\n",
    "    def __get_closed_doors(self, doors: np.ndarray, prize: np.ndarray, guesses: np.ndarray) -> np.ndarray:\n",
    "        mask_doors = (doors != guesses[:, None])\n",
    "        unchosen_doors = doors[mask_doors].reshape(-1, 2)\n",
    "        second_door = np.where(np.isin(unchosen_doors, prize).any(axis = 1), prize, unchosen_doors[:, 0])\n",
    "\n",
    "        mask_prob = np.zeros_like(unchosen_doors, dtype = np.float32)\n",
    "        for i in range(2):\n",
    "            mask_prob[:, i] = np.where(unchosen_doors[:, i] == DOOR['Left'], self.__prob[DOOR['Left']], unchosen_doors[:, i])\n",
    "            mask_prob[:, i] = np.where(unchosen_doors[:, i] == DOOR['Mid'], self.__prob[DOOR['Mid']], self.__prob[DOOR['Right']])\n",
    "        mask_prob_sum = mask_prob.sum(axis = 1)\n",
    "        mask_prob = mask_prob / mask_prob_sum[:, None]\n",
    "\n",
    "        random_picks = np.random.rand(len(mask_prob))\n",
    "        unchosen_doors_picks = np.where(random_picks < mask_prob[:, 0], unchosen_doors[:, 0], unchosen_doors[:, 1])\n",
    "\n",
    "        second_door = np.where(second_door == guesses, unchosen_doors_picks, second_door)\n",
    "        closed_doors = np.column_stack([guesses, second_door])\n",
    "\n",
    "        assert np.isin(closed_doors, prize).any(axis = 1).all(), 'No prize in closed doors'\n",
    "        assert np.isin(closed_doors, guesses).any(axis = 1).all(), 'No guess in closed doors'\n",
    "        assert np.where(closed_doors[:, 0] != closed_doors[:, 1], True, False).all(), 'Duplicate doors'\n",
    "\n",
    "        return closed_doors\n",
    "\n",
    "\n",
    "    def __simulate(self, prize: np.ndarray, model: callable, size_n: np.int32) -> np.ndarray:\n",
    "        doors = np.array([DOOR['Left'], DOOR['Mid'], DOOR['Right']])\n",
    "        doors = np.tile(doors, (size_n, 1))\n",
    "        first_guesses = model(doors)\n",
    "        closed_doors = self.__get_closed_doors(doors, prize, first_guesses)\n",
    "        return model(closed_doors, first_guesses)\n",
    "\n",
    "\n",
    "mhGame = MHGame(GAMES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaselineModel():\n",
    "    def __init__(self, name):\n",
    "        self.__run = 0\n",
    "        self.__name = name\n",
    "    \n",
    "\n",
    "    def get_model_name(self) -> str:\n",
    "        return self.__name\n",
    "\n",
    "\n",
    "    def __call__(self, doors: np.ndarray, first_guesses: Optional[np.ndarray] = None) -> np.ndarray:\n",
    "        pred = self.predict(doors, first_guesses).reshape(-1, 1)\n",
    "        assert pred.shape[0] == doors.shape[0], 'Invalid shape'\n",
    "\n",
    "        validate = np.where(np.isin(doors, pred).any(axis = 1), True, False)\n",
    "        assert validate.all(), 'Invalid door'\n",
    "\n",
    "        self.__run += 1\n",
    "        return pred.reshape(-1)\n",
    "        \n",
    "\n",
    "    def predict(self, doors: np.ndarray, first_guesses: Optional[np.ndarray] = None) -> np.ndarray:\n",
    "        return doors[:, 0]\n",
    "\n",
    "\n",
    "baselineModel = BaselineModel('Baseline')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline model: Acc -> 33.253%\n"
     ]
    }
   ],
   "source": [
    "baselineScore = mhGame.validate(baselineModel, verbose = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pure randomness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandomModel(BaselineModel):\n",
    "    def __init__(self, name):\n",
    "        super().__init__(name)\n",
    "\n",
    "    \n",
    "    def first_guess(self, doors: np.ndarray) -> np.ndarray:\n",
    "        output = np.zeros(doors.shape[0], dtype = np.int32)\n",
    "        mask = np.random.choice([True, False, False], doors.shape[0])\n",
    "        output = np.where(mask, doors[:, 0], output)\n",
    "        \n",
    "        picked = np.where(mask, True, False)\n",
    "        mask = np.random.choice([True, False], doors.shape[0])\n",
    "        output = np.where(mask & picked, doors[:, 1], doors[:, 2])\n",
    "        return output\n",
    "        \n",
    "\n",
    "    def predict(self, doors: np.ndarray, first_guesses: Optional[np.ndarray] = None) -> np.ndarray:\n",
    "        output = np.zeros(doors.shape[0], dtype = np.int32)\n",
    "        #################################\n",
    "        # Place for your code           #\n",
    "        #################################\n",
    "        return output\n",
    "        \n",
    "\n",
    "randomModel = RandomModel('Random')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random model: Acc -> 50.011%\n"
     ]
    }
   ],
   "source": [
    "randomScore = mhGame.validate(randomModel, verbose = True)\n",
    "\n",
    "assert randomScore > baselineScore, 'Random model should be better than baseline'\n",
    "assert randomScore > 0.49, 'Your model is too weak (49% accuracy is required)'\n",
    "assert randomScore < 0.51, 'Your model is too strong (51% accuracy is required)'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Change model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ChangeModel(RandomModel):\n",
    "    def __init__(self, name):\n",
    "        super().__init__(name)\n",
    "        \n",
    "\n",
    "    def predict(self, doors: np.ndarray, first_guesses: Optional[np.ndarray] = None) -> np.ndarray:\n",
    "        output = np.zeros(doors.shape[0], dtype = np.int32)\n",
    "        #################################\n",
    "        # Place for your code           #\n",
    "        #################################\n",
    "        return output\n",
    "        \n",
    "\n",
    "changeModel = ChangeModel('Change')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Change model: Acc -> 66.570%\n"
     ]
    }
   ],
   "source": [
    "changeScore = mhGame.validate(changeModel, verbose = True)\n",
    "\n",
    "assert changeScore > randomScore, 'Change model should be better than random'\n",
    "assert changeScore > 0.65, 'Your model is too weak (65% accuracy is required)'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bayes network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pgmpy.models import BayesianNetwork\n",
    "from pgmpy.factors.discrete import TabularCPD\n",
    "\n",
    "\n",
    "bayes_model = BayesianNetwork([('C', 'H'), ('P', 'H')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+----------+\n",
      "| C(0) | 0.333333 |\n",
      "+------+----------+\n",
      "| C(1) | 0.333333 |\n",
      "+------+----------+\n",
      "| C(2) | 0.333333 |\n",
      "+------+----------+\n"
     ]
    }
   ],
   "source": [
    "cpd_contestant = TabularCPD(\n",
    "    variable = 'C',\n",
    "    variable_card = 3, \n",
    "    values = [[1 / 3], [1 / 3], [1 / 3]],\n",
    ")\n",
    "\n",
    "print(cpd_contestant)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+----------+\n",
      "| P(0) | 0.333333 |\n",
      "+------+----------+\n",
      "| P(1) | 0.333333 |\n",
      "+------+----------+\n",
      "| P(2) | 0.333333 |\n",
      "+------+----------+\n"
     ]
    }
   ],
   "source": [
    "cpd_prize = TabularCPD(\n",
    "    #################################\n",
    "    # Place for your code           #\n",
    "    #################################\n",
    ")\n",
    "\n",
    "print(cpd_prize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+------+------+------+------+------+------+------+------+------+\n",
      "| C    | C(0) | C(0) | C(0) | C(1) | C(1) | C(1) | C(2) | C(2) | C(2) |\n",
      "+------+------+------+------+------+------+------+------+------+------+\n",
      "| P    | P(0) | P(1) | P(2) | P(0) | P(1) | P(2) | P(0) | P(1) | P(2) |\n",
      "+------+------+------+------+------+------+------+------+------+------+\n",
      "| H(0) | 0.0  | 0.0  | 0.0  | 0.0  | 0.5  | 1.0  | 0.0  | 1.0  | 0.5  |\n",
      "+------+------+------+------+------+------+------+------+------+------+\n",
      "| H(1) | 0.5  | 0.0  | 1.0  | 0.0  | 0.0  | 0.0  | 1.0  | 0.0  | 0.5  |\n",
      "+------+------+------+------+------+------+------+------+------+------+\n",
      "| H(2) | 0.5  | 1.0  | 0.0  | 1.0  | 0.5  | 0.0  | 0.0  | 0.0  | 0.0  |\n",
      "+------+------+------+------+------+------+------+------+------+------+\n"
     ]
    }
   ],
   "source": [
    "cpd_host = TabularCPD(\n",
    "    #################################\n",
    "    # Place for your code           #\n",
    "    #################################\n",
    ")\n",
    "\n",
    "print(cpd_host)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "bayes_model.add_cpds(cpd_contestant, cpd_prize, cpd_host)\n",
    "\n",
    "assert bayes_model.check_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from pgmpy.inference import VariableElimination\n",
    "\n",
    "class BayesModel(RandomModel):\n",
    "    def __init__(self, name, model):\n",
    "        super().__init__(name)\n",
    "        self.__model = model\n",
    "        self.__infer = VariableElimination(self.__model)\n",
    "    \n",
    "\n",
    "    def second_guess(self, doors: np.ndarray, first_guesses: np.ndarray) -> np.ndarray:\n",
    "        output = np.zeros(doors.shape[0], dtype = np.int32)\n",
    "        for i in tqdm(range(doors.shape[0]), desc = 'Second guess'):\n",
    "            #################################\n",
    "            # Place for your code           #\n",
    "            #################################\n",
    "            pass\n",
    "        return output\n",
    "        \n",
    "\n",
    "    def predict(self, doors: np.ndarray, first_guesses: Optional[np.ndarray] = None) -> np.ndarray:\n",
    "        output = np.zeros(doors.shape[0], dtype = np.int32)\n",
    "        if first_guesses is None:\n",
    "            output = self.first_guess(doors)\n",
    "        else:\n",
    "            output = self.second_guess(doors, first_guesses)\n",
    "        output = output.T\n",
    "        return output\n",
    "\n",
    "\n",
    "bayesModel = BayesModel('Bayes', bayes_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Second guess:   1%|          | 1639/200000 [00:00<00:23, 8312.85it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Second guess: 100%|██████████| 200000/200000 [00:22<00:00, 9019.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bayes model: Acc -> 66.609%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "bayesScore = mhGame.validate(bayesModel, verbose = True)\n",
    "\n",
    "assert bayesScore > randomScore, 'Bayes model should be better than random'\n",
    "assert bayesScore > 0.65, 'Your model is too weak (65% accuracy is required)'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unfair Monty Hall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unfair game\n",
      "Baseline model: Acc -> 49.730%\n",
      "Random model: Acc -> 50.047%\n",
      "Change model: Acc -> 69.117%\n"
     ]
    }
   ],
   "source": [
    "unfair_prob = np.array([0.6, 0.2, 0.4])\n",
    "unfair_prob /= unfair_prob.sum()\n",
    "\n",
    "mhGameUnfair = MHGame(GAMES, unfair_prob)\n",
    "\n",
    "print('Unfair game')\n",
    "baselineScoreUnfair = mhGameUnfair.validate(baselineModel, verbose = True)\n",
    "randomScoreUnfair = mhGameUnfair.validate(randomModel, verbose = True)\n",
    "changeScoreUnfair = mhGameUnfair.validate(changeModel, verbose = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+----------+\n",
      "| C(0) | 0.5      |\n",
      "+------+----------+\n",
      "| C(1) | 0.166667 |\n",
      "+------+----------+\n",
      "| C(2) | 0.333333 |\n",
      "+------+----------+\n"
     ]
    }
   ],
   "source": [
    "cpd_contestant_unfair = TabularCPD(\n",
    "    variable = 'C',\n",
    "    variable_card = 3, \n",
    "    values = list(unfair_prob.reshape(-1, 1).tolist()),\n",
    ")\n",
    "\n",
    "print(cpd_contestant_unfair)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+----------+\n",
      "| P(0) | 0.5      |\n",
      "+------+----------+\n",
      "| P(1) | 0.166667 |\n",
      "+------+----------+\n",
      "| P(2) | 0.333333 |\n",
      "+------+----------+\n"
     ]
    }
   ],
   "source": [
    "cpd_prize_unfair = TabularCPD(\n",
    "    variable= 'P',\n",
    "    variable_card = 3, \n",
    "    values = list(unfair_prob.reshape(-1, 1).tolist())\n",
    ")\n",
    "\n",
    "print(cpd_prize_unfair)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------------------+------+-----+------+------+------+------+------+\n",
      "| C    | C(0)               | C(0) | ... | C(1) | C(1) | C(2) | C(2) | C(2) |\n",
      "+------+--------------------+------+-----+------+------+------+------+------+\n",
      "| P    | P(0)               | P(1) | ... | P(1) | P(2) | P(0) | P(1) | P(2) |\n",
      "+------+--------------------+------+-----+------+------+------+------+------+\n",
      "| H(0) | 0.0                | 0.0  | ... | 0.6  | 1.0  | 0.0  | 1.0  | 0.75 |\n",
      "+------+--------------------+------+-----+------+------+------+------+------+\n",
      "| H(1) | 0.3333333333333333 | 0.0  | ... | 0.0  | 0.0  | 1.0  | 0.0  | 0.25 |\n",
      "+------+--------------------+------+-----+------+------+------+------+------+\n",
      "| H(2) | 0.6666666666666666 | 1.0  | ... | 0.4  | 0.0  | 0.0  | 0.0  | 0.0  |\n",
      "+------+--------------------+------+-----+------+------+------+------+------+\n"
     ]
    }
   ],
   "source": [
    "cpd_host_unfair = TabularCPD(\n",
    "    variable = 'H',\n",
    "    variable_card = 3,\n",
    "    values = [\n",
    "        [0, 0, 0, 0, 3, 1, 0, 1, 3],\n",
    "        [1, 0, 1, 0, 0, 0, 1, 0, 1],\n",
    "        [2, 1, 0, 1, 2, 0, 0, 0, 0],\n",
    "    ],\n",
    "    evidence = ['C', 'P'],\n",
    "    evidence_card = [3, 3]\n",
    ")\n",
    "cpd_host_unfair.normalize()\n",
    "\n",
    "print(cpd_host_unfair)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unfair game\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Second guess: 100%|██████████| 200000/200000 [00:21<00:00, 9145.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bayes model: Acc -> 64.770%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "bayes_model_unfair = BayesianNetwork([('C', 'H'), ('P', 'H')])\n",
    "bayes_model_unfair.add_cpds(cpd_contestant_unfair, cpd_prize_unfair, cpd_host_unfair)\n",
    "\n",
    "assert bayes_model_unfair.check_model()\n",
    "\n",
    "print('Unfair game')\n",
    "bayesModelUnfair = BayesModel('Bayes', bayes_model_unfair)\n",
    "bayesScore = mhGameUnfair.validate(bayesModelUnfair, verbose = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Can we do better?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def concat_output(ys, tag = None):\n",
    "    ys = [y.rsplit('\\n') for y in ys]\n",
    "    big_y = []\n",
    "    for i in range(len(ys[0])):\n",
    "        big_y.append(' '.join([y[i] for y in ys]))\n",
    "    return (tag + '\\n' if tag else '') + '\\n'.join(big_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Contestant Door: 0\n",
      "+------+----------+ +------+----------+\n",
      "| P    |   phi(P) | | P    |   phi(P) |\n",
      "+======+==========+ +======+==========+\n",
      "| P(0) |   0.3333 | | P(0) |   0.6667 |\n",
      "+------+----------+ +------+----------+\n",
      "| P(1) |   0.0000 | | P(1) |   0.3333 |\n",
      "+------+----------+ +------+----------+\n",
      "| P(2) |   0.6667 | | P(2) |   0.0000 |\n",
      "+------+----------+ +------+----------+\n",
      "Score: 66.667\n",
      "\n",
      "Contestant Door: 1\n",
      "+------+----------+ +------+----------+\n",
      "| P    |   phi(P) | | P    |   phi(P) |\n",
      "+======+==========+ +======+==========+\n",
      "| P(0) |   0.0000 | | P(0) |   0.8824 |\n",
      "+------+----------+ +------+----------+\n",
      "| P(1) |   0.2308 | | P(1) |   0.1176 |\n",
      "+------+----------+ +------+----------+\n",
      "| P(2) |   0.7692 | | P(2) |   0.0000 |\n",
      "+------+----------+ +------+----------+\n",
      "Score: 83.710\n",
      "\n",
      "Contestant Door: 2\n",
      "+------+----------+ +------+----------+\n",
      "| P    |   phi(P) | | P    |   phi(P) |\n",
      "+======+==========+ +======+==========+\n",
      "| P(0) |   0.0000 | | P(0) |   0.8571 |\n",
      "+------+----------+ +------+----------+\n",
      "| P(1) |   0.4000 | | P(1) |   0.0000 |\n",
      "+------+----------+ +------+----------+\n",
      "| P(2) |   0.6000 | | P(2) |   0.1429 |\n",
      "+------+----------+ +------+----------+\n",
      "Score: 75.429\n",
      "\n"
     ]
    }
   ],
   "source": [
    "infer = VariableElimination(bayes_model_unfair)\n",
    "variables = ['P']\n",
    "for contestant_door in range(3):\n",
    "    score = 0\n",
    "    total_prob = 0\n",
    "    ys = []\n",
    "    for host_door in range(3):\n",
    "        if contestant_door == host_door:\n",
    "            continue\n",
    "        evidence = {\n",
    "            'H': host_door,\n",
    "            'C': contestant_door\n",
    "        }\n",
    "        y = infer.query(variables = variables, evidence = evidence)\n",
    "        ys.append(y.__str__())\n",
    "        max_idx = y.values.argmax()\n",
    "        score += y.values[max_idx] * unfair_prob[max_idx]\n",
    "        total_prob += unfair_prob[max_idx]\n",
    "\n",
    "    score /= total_prob\n",
    "\n",
    "    print(concat_output(ys, tag=f'Contestant Door: {contestant_door}'))\n",
    "    print(f'Score: {100 * score:.3f}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Improved Random model: Acc -> 49.895%\n",
      "Improved Change model: Acc -> 83.408%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Second guess: 100%|██████████| 200000/200000 [00:22<00:00, 8948.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Improved Bayes model: Acc -> 83.408%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "class ImprovedRandomModel(RandomModel):\n",
    "    def __init__(self, name):\n",
    "        super().__init__(name)\n",
    "    \n",
    "    def first_guess(self, doors: np.ndarray) -> np.ndarray:\n",
    "        return doors[:, 1]\n",
    "\n",
    "\n",
    "class ImprovedChangeModel(ChangeModel):\n",
    "    def __init__(self, name):\n",
    "        super().__init__(name)\n",
    "    \n",
    "\n",
    "    def first_guess(self, doors: np.ndarray) -> np.ndarray:\n",
    "        return doors[:, 1]\n",
    "\n",
    "\n",
    "class ImprovedBayesModel(BayesModel):\n",
    "    def __init__(self, name, model):\n",
    "        super().__init__(name, model)\n",
    "\n",
    "   \n",
    "    def first_guess(self, doors: np.ndarray) -> np.ndarray:\n",
    "        return doors[:, 1]\n",
    "    \n",
    "\n",
    "improvedRandomModel = ImprovedRandomModel('Improved Random')\n",
    "improvedChangeModel = ImprovedChangeModel('Improved Change')\n",
    "improvedBayesModel = ImprovedBayesModel('Improved Bayes', bayes_model_unfair)\n",
    "\n",
    "improvedRandomModelScore = mhGameUnfair.validate(improvedRandomModel, verbose = True)\n",
    "improvedChangeScore = mhGameUnfair.validate(improvedChangeModel, verbose = True)\n",
    "improvedBayesScore = mhGameUnfair.validate(improvedBayesModel, verbose = True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
